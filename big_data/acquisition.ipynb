{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into spark environment (df_case, df_dept)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = spark.read.csv('case.csv', sep=\",\",\n",
    "            header=True, inferSchema=True)\n",
    "\n",
    "df_dept = spark.read.csv(\"dept.csv\", sep=\",\",\n",
    "            header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date|SLA_due_date|case_late|      num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|1014127332|     1/1/18 0:42|    1/1/18 12:29|9/26/20 0:42|       NO| -998.5087616000001|        YES|Field Operations|        Stray Animal|      999.0|     Closed| svcCRMLS|2315  EL PASO ST,...|               5|\n",
      "|1014127333|     1/1/18 0:46|     1/3/18 8:11| 1/5/18 8:30|       NO|-2.0126041669999997|        YES|     Storm Water|Removal Of Obstru...|4.322222222|     Closed| svcCRMSS|2215  GOLIAD RD, ...|               3|\n",
      "+----------+----------------+----------------+------------+---------+-------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_case.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|  dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|          Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dept.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write df_case and df_dept back to disk into their own directories (my_cases and my_depts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.csv('my_cases', header=True, mode='overwrite')\n",
    "\n",
    "df_dept.write.csv('my_depts', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write df_case and df_dept to parquet files (my_cases_parquet and my_depts_parquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.parquet('my_cases_parquet', mode='overwrite')\n",
    "\n",
    "df_dept.write.parquet('my_depts_parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read your parquet files back into your spark environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case_pq = spark.read.parquet('my_cases_parquet')\n",
    "\n",
    "df_dept_pq = spark.read.parquet('my_depts_parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+-------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date| SLA_due_date|case_late|num_days_late|case_closed|   dept_division|service_request_type|SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+-------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "|1014551581|   5/28/18 13:14|   5/28/18 14:23|5/28/18 16:14|       NO| -0.077511574|        YES|Field Operations|     Officer Standby|   0.125|     Closed|  NO10960|7003  RAVENSDALE,...|               6|\n",
      "|1014551583|   5/28/18 13:15|   5/29/18 14:38|  6/1/18 8:30|       NO| -2.743912037|        YES|Waste Collection|           No Pickup|3.801875|     Closed|   138793|1906  MOSSY CREEK...|               4|\n",
      "+----------+----------------+----------------+-------------+---------+-------------+-----------+----------------+--------------------+--------+-----------+---------+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_case_pq.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|  dept_division|           dept_name|standardized_dept_name|dept_subject_to_SLA|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "|311 Call Center|    Customer Service|      Customer Service|                YES|\n",
      "|          Brush|Solid Waste Manag...|           Solid Waste|                YES|\n",
      "+---------------+--------------------+----------------------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dept_pq.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read case.csv and dept.csv into a pandas dataframe. (cases_pdf, depts_pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_pdf = pd.read_csv('case.csv')\n",
    "depts_pdf = pd.read_csv('dept.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_division</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>standardized_dept_name</th>\n",
       "      <th>dept_subject_to_SLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311 Call Center</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brush</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clean and Green</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean and Green Natural Areas</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>DSD/Code Enforcement</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dept_division                  dept_name  \\\n",
       "0                311 Call Center           Customer Service   \n",
       "1                          Brush     Solid Waste Management   \n",
       "2                Clean and Green       Parks and Recreation   \n",
       "3  Clean and Green Natural Areas       Parks and Recreation   \n",
       "4               Code Enforcement  Code Enforcement Services   \n",
       "\n",
       "  standardized_dept_name dept_subject_to_SLA  \n",
       "0       Customer Service                 YES  \n",
       "1            Solid Waste                 YES  \n",
       "2     Parks & Recreation                 YES  \n",
       "3     Parks & Recreation                 YES  \n",
       "4   DSD/Code Enforcement                 YES  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dept_division             object\n",
       "dept_name                 object\n",
       "standardized_dept_name    object\n",
       "dept_subject_to_SLA       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the pandas dataframes into spark dataframes (cases_sdf, depts_sdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, FloatType, StructField, StringType, NumericType, IntegerType, DataType, TimestampType\n",
    "\n",
    "schema_cases = StructType([\n",
    "    StructField('case_id', IntegerType()),\n",
    "    StructField('case_opened_date', StringType()),\n",
    "    StructField('case_closed_date', StringType()),\n",
    "    StructField('SLA_due_date', StringType()),\n",
    "    StructField('case_late', StringType()),\n",
    "    StructField('num_days_late', FloatType()),\n",
    "    StructField('case_closed', StringType()),\n",
    "    StructField('dept_division', StringType()),\n",
    "    StructField('service_request_type', StringType()),\n",
    "    StructField('SLA_days', FloatType()),\n",
    "    StructField('case_status', StringType()),\n",
    "    StructField('source_id', StringType()),\n",
    "    StructField('request_address', StringType()),\n",
    "    StructField('council_district', IntegerType())\n",
    "                    ])\n",
    "\n",
    "schema_depts = StructType([\n",
    "    StructField('dept_division', StringType()),\n",
    "    StructField('dept_name', StringType()),\n",
    "    StructField('standardized_dept_name', StringType()),\n",
    "    StructField('dept_subject_to_SLA', StringType()),\n",
    "                    ])\n",
    "\n",
    "cases_sdf = spark.createDataFrame(cases_pdf, schema= schema_cases)\n",
    "depts_sdf = spark.createDataFrame(depts_pdf, schema= schema_depts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the spark dataframes back into pandas dataframes. (cases_pdf1, depts_pdf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_pdf1 = cases_sdf.toPandas()\n",
    "depts_pdf1 = depts_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the spark dataframes (cases_sdf, depts_sdf) to Hive tables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_hive = \"df_\" + str(uuid.uuid4().hex)  \n",
    "cases_sdf.write.saveAsTable(case_hive)\n",
    "\n",
    "dept_hive = \"df_\" + str(uuid.uuid4().hex)  \n",
    "depts_sdf.write.saveAsTable(dept_hive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the Hive database/tables you have created using the methods in the lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|             case_id|      int|   null|\n",
      "|    case_opened_date|   string|   null|\n",
      "|    case_closed_date|   string|   null|\n",
      "|        SLA_due_date|   string|   null|\n",
      "|           case_late|   string|   null|\n",
      "|       num_days_late|    float|   null|\n",
      "|         case_closed|   string|   null|\n",
      "|       dept_division|   string|   null|\n",
      "|service_request_type|   string|   null|\n",
      "|            SLA_days|    float|   null|\n",
      "|         case_status|   string|   null|\n",
      "|           source_id|   string|   null|\n",
      "|     request_address|   string|   null|\n",
      "|    council_district|      int|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "case_hive_query = \"DESCRIBE %s\" % case_hive\n",
    "spark.sql(case_hive_query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_c0c8449fe9f749b280b19e4aeb00b046'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|       dept_division|   string|   null|\n",
      "|           dept_name|   string|   null|\n",
      "|standardized_dept...|   string|   null|\n",
      "| dept_subject_to_SLA|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dept_hive_query = \"DESCRIBE %s\" % dept_hive\n",
    "spark.sql(dept_hive_query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_f694e2cda8e74cde853e867d58d87391'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dept_hive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read from the tables into two spark dataframes (cases_sdf, depts_sdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|             case_id|      int|   null|\n",
      "|    case_opened_date|   string|   null|\n",
      "|    case_closed_date|   string|   null|\n",
      "|        SLA_due_date|   string|   null|\n",
      "|           case_late|   string|   null|\n",
      "|       num_days_late|    float|   null|\n",
      "|         case_closed|   string|   null|\n",
      "|       dept_division|   string|   null|\n",
      "|service_request_type|   string|   null|\n",
      "|            SLA_days|    float|   null|\n",
      "|         case_status|   string|   null|\n",
      "|           source_id|   string|   null|\n",
      "|     request_address|   string|   null|\n",
      "|    council_district|      int|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE %s\" % case_hive).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|       dept_division|   string|   null|\n",
      "|           dept_name|   string|   null|\n",
      "|standardized_dept...|   string|   null|\n",
      "| dept_subject_to_SLA|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE %s\" % dept_hive).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_c0c8449fe9f749b280b19e4aeb00b046'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
